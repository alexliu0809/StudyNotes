{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NLTK - Wordnet\n",
    "[Reference1](https://xrds.acm.org/blog/2017/07/power-wordnet-use-python/)\n",
    "and\n",
    "[Reference2](http://www.nltk.org/howto/wordnet.html)\n",
    "\n",
    "[WordNet](https://wordnet.princeton.edu/) is a large lexical database of English.\n",
    "\n",
    "Take a look at the next four sentences.\n",
    "1. “She went home and had <u>pasta</u>.”\n",
    "2. “Then she cleaned the kitchen and sat on the <u>sofa</u>.”\n",
    "\n",
    "In Natural Language Processing, we try to use computer programs to find the meaning of sentences. In the above four sentences, with the help of WordNet, a computer program will be able to identify the following:\n",
    "1. “pasta” is a type of dish.\n",
    "2. “kitchen” is a part of “home”.\n",
    "\n",
    "Let’s get started with using WordNet in Python. It is included as a part of the [NLTK](http://www.nltk.org/) corpus. To use it, we need to import it first.\n",
    "```python\n",
    ">>> from nltk.corpus import wordnet as wn\n",
    "```\n",
    "### Word\n",
    "Look up a word using **synsets()**; this function has an optional pos (think of it as type) argument which lets you constrain the part of speech of the word.\n",
    "```python\n",
    ">>> wn.synsets('dog') # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
    "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'),\n",
    "Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n",
    ">>> wn.synsets('dog', pos=wn.VERB)\n",
    "[Synset('chase.v.01')]\n",
    "```\n",
    "The other parts of speech are NOUN, ADJ and ADV. A synset is identified with a 3-part name of the form: **word.pos.nn**:\n",
    "```python\n",
    ">>> wn.synset('dog.n.01')\n",
    "Synset('dog.n.01')\n",
    ">>> print(wn.synset('dog.n.01').definition())\n",
    "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
    ">>> len(wn.synset('dog.n.01').examples())\n",
    "1\n",
    ">>> print(wn.synset('dog.n.01').examples()[0])\n",
    "the dog barked all night\n",
    ">>> wn.synset('dog.n.01').lemmas()\n",
    "[Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
    ">>> [str(lemma.name()) for lemma in wn.synset('dog.n.01').lemmas()]\n",
    "['dog', 'domestic_dog', 'Canis_familiaris']\n",
    ">>> wn.lemma('dog.n.01.dog').synset()\n",
    "Synset('dog.n.01')\n",
    "```\n",
    "\n",
    "### Synonyms\n",
    "WordNet stores synonyms in the form of synsets where each word in the synset shares the same meaning. Each synset contains one or more lemmas, which represent a specific sense of a specific word. Basically, each synset is a group of synonyms. Each synset has a definition associated with it. Relations are stored between different synsets as we’ll see in the next section. Let’s explore synsets with an example.\n",
    "\n",
    "Take the word ‘sofa’. The following line in Python gives all the synsets for ‘sofa’.\n",
    "```python\n",
    ">>> wn.synsets('sofa') \n",
    "[Synset('sofa.n.01')]\n",
    "```\n",
    "We have only one synset for ‘sofa’ which means that it has only one context or meaning. Another word like ‘ocean’ will give two synsets because it has two meanings – one as ‘a water body’ and the other as ‘being limitless in quantity’.\n",
    "```python\n",
    ">>> wn.synsets('ocean') \n",
    "[Synset('ocean.n.01'), Synset('ocean.n.02')]\n",
    "```\n",
    "We can find the definition of a synset with the code given below.\n",
    "```python\n",
    ">>> wn.synset('sofa.n.01').definition()\n",
    "u'an upholstered seat for more than one person'\n",
    "```\n",
    "To find all the words that share the same meaning as sofa, we need to find all the synonyms in the sofa synset.\n",
    "```\n",
    ">>> wn.synset('sofa.n.01').lemma_names()\n",
    "[u'sofa', u'couch', u'lounge']\n",
    "```\n",
    "As can be seen above, ‘couch’ and ‘sofa’ are synonyms and share the same meaning.\n",
    "\n",
    "### Hyponyms and Hypernyms\n",
    "Hyponyms and Hypernyms are specific and generalized concepts respectively.\n",
    "\n",
    "For example, ‘beach house’ and ‘guest house’ are hyponyms of ‘house’. They are more specific concepts of ‘house’. And ‘house’ is a hypernym of ‘guest house’ because it is the general concept.\n",
    "\n",
    "‘Pasta’ is a hyponym of ‘dish’ and ‘dish’ is a hypernym of ‘pasta’.\n",
    "\n",
    "Let’s look at the code.\n",
    "\n",
    "After we find the synset whose hyponyms / hypernyms we want, the following code finds the hyponyms and hypernyms.\n",
    "\n",
    "```python\n",
    ">>> wn.synset('pasta.n.01').hyponyms() \n",
    "[Synset('cannelloni.n.01'), Synset('lasagna.n.01'), \n",
    "Synset('macaroni_and_cheese.n.01'), Synset('spaghetti.n.01')]\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> wn.synset('pasta.n.01').hypernyms()\n",
    "[Synset('dish.n.02')]\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> wn.synset('dish.n.02').definition()\n",
    "u'a particular item of prepared food'\n",
    "```\n",
    "\n",
    "As seen, we found the hyponyms and hypernym of pasta and it can be seen that pasta is a type of dish.\n",
    "\n",
    "### Meronyms and Holonyms\n",
    "Meronyms and Holonyms represent the part-whole relationship. The meronym represents the part and the holonym represents the whole. For example, ‘kitchen’ is a meronym of ‘home'(the kitchen is a part of the home), ‘bread’ is a meronym of ‘sandwich’, and ‘sandwich’ is a holonym of ‘bread’.\n",
    "\n",
    "In Python, we have –\n",
    "\n",
    "```python\n",
    ">>> wn.synsets('kitchen') \n",
    "[Synset('kitchen.n.01')]\n",
    ">>> wn.synset('kitchen.n.01').part_holonyms() \n",
    "[Synset('dwelling.n.01')]\n",
    ">>> wn.synset('kitchen.n.01').part_meronyms() \n",
    "[]\n",
    "```\n",
    "\n",
    "From the above code, we see that ‘dwelling’ is a holonym of ‘kitchen’, and so ‘kitchen’ is a meronym (or a part) of ‘dwelling’\n",
    "\n",
    "The ‘dwelling’ synset contains ‘home’ as one of its synonyms as seen below.\n",
    "```python\n",
    ">>> wn.synset('dwelling.n.01').lemma_names()\n",
    "[u'dwelling', u'home', u'domicile', \n",
    "u'abode', u'habitation', u'dwelling_house']\n",
    "```\n",
    "So we can figure out that the word ‘kitchen’ is a part of one’s ‘home’.\n",
    "\n",
    "### Similarity\n",
    "```python\n",
    ">>> dog = wn.synset('dog.n.01')\n",
    ">>> cat = wn.synset('cat.n.01')\n",
    ">>> hit = wn.synset('hit.v.01')\n",
    ">>> slap = wn.synset('slap.v.01')\n",
    "```\n",
    "synset1.path_similarity(synset2): Return a score denoting how similar two word senses are, based on the shortest path that connects the senses in the is-a (hypernym/hypnoym) taxonomy. The score is in the range 0 to 1. By default, there is now a fake root node added to verbs so for cases where previously a path could not be found---and None was returned---it should return a value. The old behavior can be achieved by setting simulate_root to be False. A score of 1 represents identity i.e. comparing a sense with itself will return 1.\n",
    "```python\n",
    ">>> dog.path_similarity(cat)  # doctest: +ELLIPSIS\n",
    "0.2...\n",
    ">>> hit.path_similarity(slap)  # doctest: +ELLIPSIS\n",
    "0.142...\n",
    ">>> wn.path_similarity(hit, slap)  # doctest: +ELLIPSIS\n",
    "0.142...\n",
    ">>> print(hit.path_similarity(slap, simulate_root=False))\n",
    "None\n",
    ">>> print(wn.path_similarity(hit, slap, simulate_root=False))\n",
    "None\n",
    "```\n",
    "synset1.lch_similarity(synset2): Leacock-Chodorow Similarity: Return a score denoting how similar two word senses are, based on the shortest path that connects the senses (as above) and the maximum depth of the taxonomy in which the senses occur. The relationship is given as -log(p/2d) where p is the shortest path length and d the taxonomy depth.\n",
    "```python\n",
    ">>> dog.lch_similarity(cat)  # doctest: +ELLIPSIS\n",
    "2.028...\n",
    ">>> hit.lch_similarity(slap)  # doctest: +ELLIPSIS\n",
    "1.312...\n",
    ">>> wn.lch_similarity(hit, slap)  # doctest: +ELLIPSIS\n",
    "1.312...\n",
    ">>> print(hit.lch_similarity(slap, simulate_root=False))\n",
    "None\n",
    ">>> print(wn.lch_similarity(hit, slap, simulate_root=False))\n",
    "None\n",
    "```\n",
    "synset1.wup_similarity(synset2): Wu-Palmer Similarity: Return a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node). Note that at this time the scores given do _not_ always agree with those given by Pedersen's Perl implementation of Wordnet Similarity.\n",
    "\n",
    "The LCS does not necessarily feature in the shortest path connecting the two senses, as it is by definition the common ancestor deepest in the taxonomy, not closest to the two senses. Typically, however, it will so feature. Where multiple candidates for the LCS exist, that whose shortest path to the root node is the longest will be selected. Where the LCS has multiple paths to the root, the longer path is used for the purposes of the calculation.\n",
    "```python\n",
    ">>> dog.wup_similarity(cat)  # doctest: +ELLIPSIS\n",
    "0.857...\n",
    ">>> hit.wup_similarity(slap)\n",
    "0.25\n",
    ">>> wn.wup_similarity(hit, slap)\n",
    "0.25\n",
    ">>> print(hit.wup_similarity(slap, simulate_root=False))\n",
    "None\n",
    ">>> print(wn.wup_similarity(hit, slap, simulate_root=False))\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
