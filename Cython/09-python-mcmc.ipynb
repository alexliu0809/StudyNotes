{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC with Python / NumPy / Scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code shamelessly stolen and adapted from Thomas Wiecki's blog, [**While my MCMC Gently Samples**](http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/)\n",
    "\n",
    "Other resources and Python libraries:\n",
    "* [PyMC3](https://pymc-devs.github.io/pymc3/index.html) -- Bayesian statistical modeling and Probabilistic Machine Learning package which focuses on advanced Markov chain Monte Carlo and variational fitting algorithms.\n",
    "* [emcee -- the MCMC Hammer](http://dan.iel.fm/emcee/current/) -- The Python ensemble sampling toolkit for affine-invariant MCMC.\n",
    "* [Edward](http://edwardlib.org/) -- Python library for probabilistic modeling, inference, and criticism that fuses three fields: Bayesian statistics and machine learning, deep learning, and probabilistic programming.\n",
    "\n",
    "Our goals in this section are very modest: we will start with a simple pure-Python MCMC sampler for a very simple Bayesian model and progressively improve its performance with Cython.\n",
    "\n",
    "The core goal is to demonstrate advanced Cython capabilites in the context of Bayesian statistical modeling.\n",
    "\n",
    "An ancilliary goal is to better understand the inner workings of MCMC samplers for Bayesian modeling, in the spirit of Feynman:\n",
    "\n",
    "_\"What I cannot create, I do not understand.\"_\n",
    "\n",
    "The algorithm used here is very simple; there are much more sophisticated and efficient MCMC algorithms implemented in the packages above.  If you're doing things for real, then you should be using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sampled from standard normal\n",
    "\n",
    "Our goal will be to estimate the posterior of the mean $\\mu$ assuming that we know the standard deviation $\\sigma$ to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.random.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "sns.distplot(data, kde=False, ax=ax)\n",
    "_ = ax.set(title='Histogram of observed data', xlabel='x', ylabel='# observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our model\n",
    "\n",
    "Normals everywhere!\n",
    "\n",
    "Prior distribution on $\\mu$:\n",
    "\n",
    "$$p(\\mu) = N(0, 1)$$\n",
    "\n",
    "Likelihood:\n",
    "\n",
    "$$p(x|\\mu) = N(x | \\mu, 1)$$\n",
    "\n",
    "For this simple model, our posterior also takes the form of a normal distribution:\n",
    "\n",
    "$$p(\\mu|x) = N(\\mu | \\mu_p, \\sigma_p)$$.\n",
    "\n",
    "See [here](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxiYXllc2VjdHxneDplNGY0MDljNDA5MGYxYTM) for the derivation of $\\mu_p$ and $\\sigma_p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_posterior_analytical(data, x, mu_0, sigma_0):\n",
    "    sigma = 1.\n",
    "    n = len(data)\n",
    "    mu_post = (mu_0 / sigma_0**2 + data.sum() / sigma**2) / (1. / sigma_0**2 + n / sigma**2)\n",
    "    sigma_post = (1. / sigma_0**2 + n / sigma**2)**-1\n",
    "    return norm(mu_post, np.sqrt(sigma_post)).pdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "x = np.linspace(-1, 1, 500)\n",
    "posterior_analytical = calc_posterior_analytical(data, x, 0., 1.)\n",
    "ax.plot(x, posterior_analytical)\n",
    "ax.set(xlabel='mu', ylabel='belief', title='Analytical posterior');\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Sampler\n",
    "\n",
    "Rather than compute our posterior analytically which can be intractable for more complex models, we want to generate samples from the posterior.  The magic of MCMC is that it can generate these samples without computing the full posterior; all it needs is an unnormalized distribution that is _proportional_ to the posterior as given by Bayes' Theorem:\n",
    "\n",
    "$$p(\\mu|x) = \\frac{p(x|\\mu) p(\\mu)}{p(x)} \\propto p(x|\\mu) p(\\mu)$$\n",
    "\n",
    "The [basic MCMC algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) proceeds as follows:\n",
    "\n",
    "1. We're given an initial value for $\\mu_{current}$.\n",
    "1. We sample a proposed $\\mu_{prop}$ from a proposal distribution for $\\mu \\sim N(\\mu|\\mu_{current}, \\sigma_{prop})$.\n",
    "1. We compute the likelihood of our data, $x$, given $\\mu_{prop}$, $p(x|\\mu_{prop})$.\n",
    "1. We then compute an acceptance probability as the following ratio:\n",
    "$$ p_{accept} = \\frac{p(x|\\mu_{prop}) p(\\mu_{prop})}{p(x|\\mu_{current})p(\\mu_{current})}$$\n",
    "1. We assign $\\mu_{current} = \\mu_{prop}$ with probability:\n",
    "$$\\min(1, p_{accept})$$\n",
    "otherwise $\\mu_{current}$ remains unchanged.\n",
    "1. We repeat these steps many times, and generate a sequence of values for $\\mu$ sampled from the posterior distribution.\n",
    "\n",
    "There are many, many improvments on this base MCMC algorithm to make it more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampler(data, samples=4, mu_init=.5, proposal_width=.5, plot=False, mu_prior_mu=0, mu_prior_sd=1.):\n",
    "    mu_current = mu_init\n",
    "    posterior = [mu_current]\n",
    "    for i in range(samples):\n",
    "        # suggest new position\n",
    "        mu_proposal = norm(mu_current, proposal_width).rvs()\n",
    "\n",
    "        # Compute likelihood by multiplying probabilities of each data point\n",
    "        likelihood_current = norm(mu_current, 1).pdf(data).prod()\n",
    "        likelihood_proposal = norm(mu_proposal, 1).pdf(data).prod()\n",
    "        \n",
    "        # Compute prior probability of current and proposed mu        \n",
    "        prior_current = norm(mu_prior_mu, mu_prior_sd).pdf(mu_current)\n",
    "        prior_proposal = norm(mu_prior_mu, mu_prior_sd).pdf(mu_proposal)\n",
    "        \n",
    "        p_current = likelihood_current * prior_current\n",
    "        p_proposal = likelihood_proposal * prior_proposal\n",
    "        \n",
    "        # Accept proposal?\n",
    "        p_accept = p_proposal / p_current\n",
    "        \n",
    "        # Usually would include prior probability, which we neglect here for simplicity\n",
    "        accept = np.random.rand() < p_accept\n",
    "        \n",
    "        if plot:\n",
    "            plot_proposal(mu_current, mu_proposal, mu_prior_mu, mu_prior_sd, data, accept, posterior, i)\n",
    "        \n",
    "        if accept:\n",
    "            # Update position\n",
    "            mu_current = mu_proposal\n",
    "        \n",
    "        posterior.append(mu_current)\n",
    "        \n",
    "    return posterior\n",
    "\n",
    "# Function to display\n",
    "def plot_proposal(mu_current, mu_proposal, mu_prior_mu, mu_prior_sd, data, accepted, trace, i):\n",
    "    from copy import copy\n",
    "    trace = copy(trace)\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, figsize=(16, 4))\n",
    "    fig.suptitle('Iteration %i' % (i + 1))\n",
    "    x = np.linspace(-3, 3, 5000)\n",
    "    color = 'g' if accepted else 'r'\n",
    "        \n",
    "    # Plot prior\n",
    "    prior_current = norm(mu_prior_mu, mu_prior_sd).pdf(mu_current)\n",
    "    prior_proposal = norm(mu_prior_mu, mu_prior_sd).pdf(mu_proposal)\n",
    "    prior = norm(mu_prior_mu, mu_prior_sd).pdf(x)\n",
    "    ax1.plot(x, prior)\n",
    "    ax1.plot([mu_current] * 2, [0, prior_current], marker='o', color='b')\n",
    "    ax1.plot([mu_proposal] * 2, [0, prior_proposal], marker='o', color=color)\n",
    "    ax1.annotate(\"\", xy=(mu_proposal, 0.2), xytext=(mu_current, 0.2),\n",
    "                 arrowprops=dict(arrowstyle=\"->\", lw=2.))\n",
    "    ax1.set(ylabel='Probability Density', title='current: prior(mu=%.2f) = %.2f\\nproposal: prior(mu=%.2f) = %.2f' % (mu_current, prior_current, mu_proposal, prior_proposal))\n",
    "    \n",
    "    # Likelihood\n",
    "    likelihood_current = norm(mu_current, 1).pdf(data).prod()\n",
    "    likelihood_proposal = norm(mu_proposal, 1).pdf(data).prod()\n",
    "    y = norm(loc=mu_proposal, scale=1).pdf(x)\n",
    "    sns.distplot(data, kde=False, norm_hist=True, ax=ax2)\n",
    "    ax2.plot(x, y, color=color)\n",
    "    ax2.axvline(mu_current, color='b', linestyle='--', label='mu_current')\n",
    "    ax2.axvline(mu_proposal, color=color, linestyle='--', label='mu_proposal')\n",
    "    #ax2.title('Proposal {}'.format('accepted' if accepted else 'rejected'))\n",
    "    ax2.annotate(\"\", xy=(mu_proposal, 0.2), xytext=(mu_current, 0.2),\n",
    "                 arrowprops=dict(arrowstyle=\"->\", lw=2.))\n",
    "    ax2.set(title='likelihood(mu=%.2f) = %.2f\\nlikelihood(mu=%.2f) = %.2f' % (mu_current, 1e14*likelihood_current, mu_proposal, 1e14*likelihood_proposal))\n",
    "    \n",
    "    # Posterior\n",
    "    posterior_analytical = calc_posterior_analytical(data, x, mu_prior_mu, mu_prior_sd)\n",
    "    ax3.plot(x, posterior_analytical)\n",
    "    posterior_current = calc_posterior_analytical(data, mu_current, mu_prior_mu, mu_prior_sd)\n",
    "    posterior_proposal = calc_posterior_analytical(data, mu_proposal, mu_prior_mu, mu_prior_sd)\n",
    "    ax3.plot([mu_current] * 2, [0, posterior_current], marker='o', color='b')\n",
    "    ax3.plot([mu_proposal] * 2, [0, posterior_proposal], marker='o', color=color)\n",
    "    ax3.annotate(\"\", xy=(mu_proposal, 0.2), xytext=(mu_current, 0.2),\n",
    "                 arrowprops=dict(arrowstyle=\"->\", lw=2.))\n",
    "    #x3.set(title=r'prior x likelihood $\\propto$ posterior')\n",
    "    ax3.set(title='posterior(mu=%.2f) = %.5f\\nposterior(mu=%.2f) = %.5f' % (mu_current, posterior_current, mu_proposal, posterior_proposal))\n",
    "    \n",
    "    if accepted:\n",
    "        trace.append(mu_proposal)\n",
    "    else:\n",
    "        trace.append(mu_current)\n",
    "    ax4.plot(trace)\n",
    "    ax4.set(xlabel='iteration', ylabel='mu', title='trace')\n",
    "    plt.tight_layout()\n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "sampler(data, samples=20, mu_init=-1., plot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "posterior = sampler(data, samples=15000, mu_init=1.)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(posterior)\n",
    "_ = ax.set(xlabel='sample', ylabel='mu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "\n",
    "sns.distplot(posterior[500:], ax=ax, label='estimated posterior')\n",
    "x = np.linspace(-.7, .9, 500)\n",
    "post = calc_posterior_analytical(data, x, 0, 1)\n",
    "ax.plot(x, post, 'g', label='analytic posterior')\n",
    "_ = ax.set(xlabel='mu', ylabel='belief');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
