{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up Pandas' GroupBy with Cython\n",
    "\n",
    "Scenario: we have a large dataframe [comprising](https://en.wikipedia.org/wiki/User:Giraffedata/comprised_of) several smaller tables concatenated together.\n",
    "\n",
    "We've done all our data cleaning and munging on the columns of the large dataframe, and we need to break it up into small dataframes.  This scenario may, hypothetically, come up when doing sequence modeling with recurrent neural networks, and we need to prepare mini-batches of sequences for our model to train against.\n",
    "\n",
    "A straightforward way to do it is `list(df.groupby(level=0, sort=False))`.  Unfortunately, Pandas can be really slow in this case -- making lots of little dataframes is an expensive operation.\n",
    "\n",
    "Since we know certain constraints are satisfied, can we speed this up with NumPy and Cython?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from uuid import uuid4\n",
    "import toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nblocks = 10000\n",
    "rowsperblock = np.random.randint(1, 7, size=nblocks)\n",
    "ncols = 3\n",
    "\n",
    "idx = list(toolz.concat([[uuid4().hex] * rpb for rpb in rowsperblock]))\n",
    "df = pd.DataFrame(np.random.standard_normal(size=(rowsperblock.sum(), ncols)), index=idx)\n",
    "print(df.info())\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.is_monotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.groupby(level=[0], sort=False))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit list(df.groupby(level=[0], sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun list(df.groupby(level=[0], sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating lots of little dataframes is expensive\n",
    "* Pandas doesn't have a fast path for DataFrame creation with data that's already clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy version\n",
    "\n",
    "* For this problem, we're willing to adjust the output and generate a sequence of NumPy arrays rather than a sequence of dataframes.\n",
    "* With this adjustment, we'll see we can get a substantial speedup using NumPy operations.\n",
    "* Once it's rewritten to use NumPy, then we can get *further* speedups with Cython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitby(df):\n",
    "    idx = df.index\n",
    "    # NumPy array of \"posts\" that delineate the row indices\n",
    "    # with which to split the dataframe.\n",
    "    posts = np.where(idx[1:] != idx[:-1])[0] + 1\n",
    "    split_labels = idx[np.concatenate([[0], posts, [-1]])]\n",
    "    split_data = np.split(df.values, posts, 0)\n",
    "    return list(zip(split_labels, split_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitby(df)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit splitby(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* Why is this faster?\n",
    "* What about `DataFrame.iloc`?  Can it give us fast slicing without the overhead?  Why or why not?\n",
    "* If we double the number of columns, how do you expect the two versions to scale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Cython version\n",
    "\n",
    "* With room for improvement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "cimport cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "\n",
    "def splitby_cython(df):\n",
    "    cols = df.values\n",
    "    idx = df.index.values\n",
    "    n = idx.shape[0]\n",
    "    result = []\n",
    "    thispost = 0\n",
    "        \n",
    "    for i in range(1, n):\n",
    "        if idx[i] != idx[i-1]:\n",
    "            result.append((idx[i-1], cols[thispost:i]))\n",
    "            thispost = i\n",
    "            \n",
    "    result.append((idx[i-1], cols[thispost:]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit splitby_cython(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* Use constructs and patterns from previous notebooks to improve this result.\n",
    "\n",
    "Some pointers:\n",
    "* Think about how you can give Cython more type information to convert Python objects into C equivalents.\n",
    "* Good candidates:\n",
    "  * Loop indexing vars, arguments to `range()`.\n",
    "  * NumPy arrays with `cdef cnp.ndarray[double] xyz = ...`.\n",
    "  * Statically declaring `list` and other Python types.\n",
    "* Remember the `@cython.boundcheck(False)` and `@cython.wraparound(False)` decorators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
